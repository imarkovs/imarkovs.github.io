
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="uq">1</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Kaviani, I.&nbsp;Markovsky, and H.&nbsp;Ossareh.
 Uncertainty quantification of data-driven output predictors in the
  output error setting.
 <em>IEEE Trans. Automat. Contr.</em>, 2026.
[&nbsp;<a href="j_bib.html#uq">bib</a>&nbsp;]
<blockquote>
We revisit the problem of predicting the output of an LTI system directly using offline input-output data (and without the use of a parametric model) in the behavioral setting. Existing works calculate the output predictions by projecting the recent samples of the input and output signals onto the column span of a Hankel matrix consisting of the offline input-output data. However, if the offline data is corrupted by noise, the output prediction is no longer exact. While some prior works propose mitigating noisy data through matrix low-ranking approximation heuristics, such as truncated singular value decomposition, the ensuing prediction accuracy remains unquantified. This paper fills these gaps by introducing two upper bounds on the prediction error under the condition that the noise is sufficiently small relative to the offline data’s magnitude. The first bound pertains to prediction using the raw offline data directly, while the second one applies to the case of a low-ranking approximation heuristic. Notably, the bounds do not require the ground truth about the system output, relying solely on noisy measurements with a known noise level and system order. Extensive numerical simulations show that both bounds decrease monotonically (and linearly) as a function of the noise level. Furthermore, our results demonstrate that applying the de-noising heuristic in the output error setup does not generally lead to a better prediction accuracy as compared to using raw data directly, nor a smaller upper bound on the prediction error. However, it allows for a more general upper bound, as the first upper bound requires a specific condition on the partitioning of the Hankel matrix.
</blockquote>
<p><blockquote>
Keywords: Uncertainty quantification, data-driven control, output prediction error bounds, truncated singular value decomposition de-noising
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="lpv-fl">2</a>]
</td>
<td class="bibtexitem">
C.&nbsp;Verhook, I.&nbsp;Markovsky, S.&nbsp;Haesaert, and R.&nbsp;Toth.
 The behavioral approach for LPV data-driven representations.
 <em>IEEE Trans. Automat. Contr.</em>, 2026.
[&nbsp;<a href="j_bib.html#lpv-fl">bib</a>&nbsp;]
<blockquote>
This paper uses the behavioral approach for linear parameter-varying (LPV) systems to develop a data-driven representation of the finite-horizon behavior of an LPV system with shifted-affine scheduling dependence. We present a necessary and sufficient condition to verify whether a system trajectory is sufficiently rich to represent the full finite-horizon behavior. This condition is a simple rank condition on a matrix constructed from the data and is thus directly verifiable from data. The result is used to solve the LPV data-driven simulation problem and a simulation example is presented.
</blockquote>
<p><blockquote>
Keywords: behavioral systems theory, linear parameter-varying systems, data-driven simulation and control
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jan-new">3</a>]
</td>
<td class="bibtexitem">
M.&nbsp;Alsalti, I.&nbsp;Markovsky, V.&nbsp;G. Lopez, and M.&nbsp;A. Müller.
 Data-based system representations from irregularly measured data.
 <em>IEEE Trans. Automat. Contr.</em>, 70:143--158, 2025.
[&nbsp;<a href="j_bib.html#jan-new">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2024.3423053">DOI</a>&nbsp;| 
<a href="https://arxiv.org/pdf/2307.11589">pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ode-improved">4</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi, K.&nbsp;Usevich, and I.&nbsp;Markovsky.
 Implementation improvements and extensions of an ODE-based
  algorithm for structured low-rank approximation.
 <em>Calcolo</em>, 60(2), 2025.
[&nbsp;<a href="j_bib.html#ode-improved">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s10092-024-00623-y">DOI</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bias-correction-vandermonde-matrix">5</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi, A.&nbsp;Kukush, and I.&nbsp;Markovsky.
 Bias correction for Vandermonde low-rank approximation.
 <em>Econometrics and Statistics</em>, 31:38--48, 2024.
[&nbsp;<a href="j_bib.html#bias-correction-vandermonde-matrix">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.ecosta.2021.09.001">DOI</a>&nbsp;]
<blockquote>
The low-rank approximation problem, that is  the problem of approximating a given matrix with a matrix of lower rank, appears in many scientific fields. In some applications the given matrix is structured and the approximation is required to have the same structure. Examples of linear structures are Hankel, Toeplitz, and Sylvester. Currently, there are only a few results for nonlinearly structured low-rank approximation problems.  The problem of Vandermonde structured low-rank approximation is considered. The high condition number of the Vandermonde matrix, in combination with the noise in the data, makes the problem challenging. A numerical method based on a bias correction procedure is proposed and its properties  are shown. The performance of the method is illustrated on numerical results.
</blockquote>
<p><blockquote>
Keywords: Vandermonde matrix, bias removal, adjusted least squares,  structured matrix perturbation
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="frest">6</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and H.&nbsp;Ossareh.
 Finite-data nonparametric frequency response evaluation without
  leakage.
 <em>Automatica</em>, 159:111351, 2024.
[&nbsp;<a href="j_bib.html#frest">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2023.111351">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/frest.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/frest">software</a>&nbsp;]
<blockquote>
The existing nonparametric frequency response estimation methods suffer from leakage and have limited frequency resolution. Due to the leakage and interpolation errors these methods do not yield the correct result in case of exact data of a linear time-invariant system. Our main contribution is a nonparameteric direct data-driven frequency response estimation method that in case of exact data satisfying standard persistency of excitation condition eliminates the leakage and has infinite frequency resolution. The method is derived in the behavioral setting. It requires solving a system of linear equations and has no hyper-parameters. In case of noisy data, a modification of the method with low-rank approximation result in an effective frequency response estimator.
</blockquote>
<p><blockquote>
Keywords: direct data-driven methods, frequency response estimation, behavioral approach, leakage elimination.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mpum-md">7</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, M.&nbsp;Alsalti, V.&nbsp;G. Lopez, and M.&nbsp;A. Müller.
 Identification from data with periodically missing output samples.
 <em>Automatica</em>, 169:111869, 2024.
[&nbsp;<a href="j_bib.html#mpum-md">bib</a>&nbsp;| 
<a href="https://doi.org/10.1016/j.automatica.2024.111869">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/mpum-periodic-md.pdf">pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia-csl">8</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Wang, L.&nbsp;Hemelhof, I.&nbsp;Markovsky, and P.&nbsp;Patrinos.
 A trust-region method for data-driven iterative learning control of
  nonlinear systems.
 <em>Control Systems Letters</em>, 8:1847--1852, 2024.
[&nbsp;<a href="j_bib.html#jia-csl">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/LCSYS.2024.3417805">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/jia-csl.pdf">pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bridging">9</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Dörfler, J.&nbsp;Coulson, and I.&nbsp;Markovsky.
 Bridging direct &amp; indirect data-driven control formulations via
  regularizations and relaxations.
 <em>IEEE Trans. Automat. Contr.</em>, 68:883--897, 2023.
[&nbsp;<a href="j_bib.html#bridging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2022.3148374">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/2101.01273">pdf</a>&nbsp;]
<blockquote>
We discuss connections between sequential system identification and control for linear time-invariant systems, which we term indirect data-driven control, as well as a direct data-driven control approach seeking an optimal decision compatible with recorded data assembled in a Hankel matrix and robustified through suitable regularizations. We formulate these two problems in the language of behavioral systems theory and parametric mathematical programs, and we bridge them through a multi-criteria formulation trading off system identification and control objectives. We illustrate our results with two methods from subspace identification and control: namely, subspace predictive control and low-rank approximation which constrain trajectories to be consistent with a non-parametric predictor derived from (respectively, the column span of) a data Hankel matrix. In both cases we conclude that direct and regularized data-driven control can be derived as convex relaxation of the indirect approach, and the regularizations account for an implicit identification step. Our analysis further reveals a novel regularizer and sheds light on the remarkable performance of direct methods on nonlinear systems.
</blockquote>
<p><blockquote>
Keywords: multi-objective optimization, system identification, data-driven control, DeePC, behavioral system theory
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ddsim-narx">10</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Data-driven simulation of generalized bilinear systems via linear
  time-invariant embedding.
 <em>IEEE Trans. Automat. Contr.</em>, 68:1101--1106, 2023.
[&nbsp;<a href="j_bib.html#ddsim-narx">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2022.3146726">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/ddsim-narx.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/ddsim.tar">software</a>&nbsp;]
<blockquote>
Nonparameteric representations of linear time-invariant systems that use Hankel matrices constructed from data are the basis for data-driven signal processing and control methods of linear time-invariant systems. This paper extends the approach to data-driven simulation of a class of nonlinear systems. The key step of the generalization is an embedding result that is also of independent interest. The behavior of a polynomial time-invariant system is included into the behavior of a linear time-invariant system. A subclass of polynomial time-invariant systems that leads to a computationally tractable data-driven simulation problem is generalized bilinear. It includes Hammerstein, finite-lag Volterra, and biliner systems. The method proposed is illustrated and compared with the classical model-based method on simulation examples in the errors-invariables setup as well as benchmark real-life data sets.
</blockquote>
<p><blockquote>
Keywords: behavioral approach, system identification, data-driven methods, nonlinear systems.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="fl">11</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, E.&nbsp;Prieto-Araujo, and F.&nbsp;Dörfler.
 On the persistency of excitation.
 <em>Automatica</em>, page 110657, 2023.
[&nbsp;<a href="j_bib.html#fl">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2022.110657">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/fl-rev.pdf">pdf</a>&nbsp;]
<blockquote>
The result of J.C. Willems et al. “A note on persistency of excitation”, System &amp; Control Letters, 2005 gives identifiability conditions for system identification as well as data-driven representations for data-driven control. The existing proofs however are proofs by contradiction and do not give insight into the assumptions of controllability and persistency of excitation of the input. Moreover, the existing proofs do not clarify how conservative the assumptions are. We provide an alternative constructive proof that reduces the required order of persistency of excitation to the time horizon of the data-driven representation plus the controllability index of the system. The nongeneric case in which persistency of excitation of order more than the time horizon is needed corresponds to special initial condition. It is explicitly characterized in terms of the solution of a Sylvester equation. Another contribution of the paper is a representation of a persistently exciting input of a specified order as an output of an autonomous linear time-invariant system. The result can be used for input design with constraints on the input.
</blockquote>
<p><blockquote>
Keywords: behavioral approach; exact identification; identifiability; persistency of excitation; input design
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="identifiability">12</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and F.&nbsp;Dörfler.
 Identifiability in the behavioral setting.
 <em>IEEE Trans. Automat. Contr.</em>, 68:1667--1677, 2023.
[&nbsp;<a href="j_bib.html#identifiability">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2022.3209954">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/identifiability.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/identifiability-code.pdf">software</a>&nbsp;]
<blockquote>
The behavioral approach to system identification starts from a given time series without a priori separation of the variables into inputs and outputs. The available identifiability conditions however require persistency of excitation of an input component of the time series which implicitly assumes that an input/output partitioning of the variables is given. In addition, a standard identifiability assumption is that the true data generating system is controllable. The conditions of controllability and persistency of excitation are sufficient but not necessary.<p>
Motivated by the need to infer linear-time invariant models from rank deficient Hankel matrices and to use such matrices as data-driven predictors in signal processing and control, we derive necessary and sufficient identifiability conditions that do not require a priori given input/output partitioning of the variables nor controllability of the true system. The prior knowledge needed for identifiability is the number of inputs, lag, and order of the true system. The results are based on a modification of the notion of a most powerful unfalsified model for finite data and a novel algorithm for its computation. <p>
The results in the paper are derived assuming exact data, however, low-rank approximation allows their application in the case of noisy data. We compare empirically low-rank approximation of the Hankel, Page, and trajectory matrices in the errors-in-variables setting. Although the Page and trajectory matrices are unstructured, the parameter estimates obtained from them are less accurate than the one obtained from the Hankel matrix.

</blockquote>
<p><blockquote>
Keywords: Behavioral system theory, System identification, Most powerful unfalsified model, Hankel matrix.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="tutorial">13</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, L.&nbsp;Huang, and F.&nbsp;Dörfler.
 Data-driven control based on behavioral approach: From theory to
  applications in power systems.
 <em>IEEE Control Systems Magazine</em>, 43:28--68, 2023.
[&nbsp;<a href="j_bib.html#tutorial">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/MCS.2023.3291638">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/tutorial.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/tutorial">software</a>&nbsp;]
<blockquote>
Behavioral systems theory decouples the behavior of a system from its representation. A key result is that, under a persistency of excitation condition, the image of a Hankel matrix constructed from the data equals the set of finite-length trajectories of a linear time-variant system. The result is the cornerstone of a recently emerged approach to direct data-driven control. This self-contained tutorial reviews its foundations and shows how they can be leveraged for data-driven control. We present a generic data-driven interpolation / approximation formulation encompassing many well known problem instances, among others finite-horizon data-driven control. We embed this problem formulation into a predictive control setting, robustify it to inexact data by means of regularizations, and apply the resulting methods in the context of power electronics dominated power systems.
</blockquote>
<p><blockquote>
Keywords: Data-driven control, Behavioral system theory, System identification, Power electronics.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="beh-dist-ejc">14</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi and I.&nbsp;Markovsky.
 Distance problems in the behavioral setting.
 <em>European Journal of Control</em>, 74:100832, 2023.
[&nbsp;<a href="j_bib.html#beh-dist-ejc">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.ejcon.2023.100832">DOI</a>&nbsp;]
<blockquote>
Motivated by the distance to uncontrollability problem, we define a distance between finite-length linear timeinvariant systems. The method proposed in this paper for computing the distance exploits the principal angles associated with structured matrices representing the systems.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="addition-and-intersection">15</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi and I.&nbsp;Markovsky.
 Addition and intersection of linear time-invariant behaviors.
 <em>IFAC Journal of Systems and Control</em>, 26:100233, 2023.
[&nbsp;<a href="j_bib.html#addition-and-intersection">bib</a>&nbsp;| 
<a href="https://doi.org/10.1016/j.ifacsc.2023.100233">DOI</a>&nbsp;]
<blockquote>
We define and analyze the operations of addition and intersection of linear time-invariant systems in the behavioral setting, where systems are viewed as sets of trajectories rather than input-output maps. The classical definition of addition of input-output systems is addition of the outputs with the inputs being equal. In the behavioral setting, addition of systems is defined as addition of all variables. Intersection of linear time-invariant systems was considered before only for the autonomous case in the context of "common dynamics" estimation. We generalize the notion of common dynamics to open systems (systems with inputs) as intersection of behaviors. This is done by proposing a trajectory-based definition of these two basic operations. The main results of the paper are 1) characterization of the link between  the complexities (number of inputs and order) of the sum and intersection systems, 2) algorithms for computing their kernel and image representations and 3) show a duality property of the two operations. Despite these operations not being new to the literature, we highlight that the proposed approach is different, and based on polynomial computations and linear algebra.
</blockquote>
<p><blockquote>
Keywords: System identification, Missing data, Behavioral approach, Lifting
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ddint">16</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and F.&nbsp;Dörfler.
 Data-driven dynamic interpolation and approximation.
 <em>Automatica</em>, 135:110008, 2022.
[&nbsp;<a href="j_bib.html#ddint">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2021.110008">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/ddint.pdf">pdf</a>&nbsp;]
<blockquote>
The behavioral system theory and in particular a result that became known as the "fundamental lemma" give the theoretical foundation for nonparameteric representations of linear time-invariant systems based on Hankel matrices constructed from data. These "data-driven" representations led in turn to new system identification, signal processing, and control methods. This paper shows how the approach can be used further on for solving interpolation, extrapolation, and smoothing problems. The solution proposed and the resulting method are general---can deal simultaneously with missing, exact, and noisy data of multivariable systems---and simple---require only the solution of a linear system of equations. In the case of exact data, we provide conditions for existence and uniqueness of solution. In the case of noisy data, we propose an approximation procedure based on <I>_1</I>-norm regularization and validate its performance on real-life datasets. The method proposed outperforms model-based approaches. Procedures used in subspace identification, such as computation of a set of free responses and zero-initial conditions responses, are recovered as special cases of the data-driven interpolation method in the paper. The results have application in missing data estimation and trajectory planning. They open a practical computational way of doing system theory and signal processing directly from data without identification of a transfer function or state-space system representation.
</blockquote>
<p><blockquote>
Keywords: behavioral approach, system identification, data-driven methods, dynamic interpolation, missing data estimation, smoothing
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="known-degrees">17</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi, B.&nbsp;Grossmann, G.&nbsp;Merc&egrave;re, and I.&nbsp;Markovsky.
 Mimo system identification using common denominator and numerators
  with known degrees.
 <em>International Journal of Adaptive Control and Signal
  Processing</em>, 36(4):870--881, 2022.
[&nbsp;<a href="j_bib.html#known-degrees">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1002/acs.3380">DOI</a>&nbsp;| 
<a href="https://github.com/fazziant/Computational-methods/blob/master/MIMO%20system%20identification.pdf">.pdf</a>&nbsp;]
<blockquote>
In system identification, prior knowledge about the model structure may be available. However, imposing this structure on the identified model may be nontrivial. A new discrete-time linear time-invariant identification method is presented in the paper that imposes prior knowledge of the degree of the common denominator of the system's transfer function matrix and the degrees of the numerators. First, a method is outlined for the solution in case of exact data. Then, this method is extended for noisy data in the output error setting. An initial estimate obtained by a subspace method is improved by a structured low-rank approximation method. The performance of the method imposing the structure is compared on simulated data with the performance of classical identification methods that do not impose the structure.
</blockquote>
<p><blockquote>
Keywords: System Identification, Structural Prior, Discrete-time systems, Subspace Methods, Structured Low-Rank Approximation
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hankel-ode">18</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi, N.&nbsp;Guglielmi, and I.&nbsp;Markovsky.
 A gradient system approach for Hankel structured low-rank
  approximation.
 <em>Linear Algebra Appl.</em>, 623:236--257, 2021.
[&nbsp;<a href="j_bib.html#hankel-ode">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.laa.2020.11.016">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/2002.06621v3">pdf</a>&nbsp;]
<blockquote>
Rank deficient Hankel matrices are at the core of several applications. However, in practice, the coefficients of these matrices are noisy due to e.g. measurements errors and computational errors, so generically the involved matrices are full rank. This motivates the problem of Hankel structured low-rank approximation. Structured low-rank approximation problems, in general, do not have a global and efficient solution technique. In this paper we propose a local optimization approach based on a two-levels iteration. Experimental results show that the proposed algorithm usually achieves good accuracy and shows a higher robustness with respect to the initial approximation, compared to alternative approaches.
</blockquote>
<p><blockquote>
Keywords: Hankel matrix, low-rank approximation, gradient system, structured matrix perturbation
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="set-exact-models">19</a>]
</td>
<td class="bibtexitem">
V.&nbsp;Mishra and I.&nbsp;Markovsky.
 The set of linear time-invariant unfalsified models with bounded
  complexity is affine.
 <em>IEEE Trans. Automat. Contr.</em>, 66:4432--4435, 2021.
[&nbsp;<a href="j_bib.html#set-exact-models">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2020.3046235">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/set-exact-models.pdf">pdf</a>&nbsp;]
<blockquote>
We consider exact system identification in the behavioral setting: given an exact (noise-free) finite time series, find the set of bounded complexity linear time-invariant systems that fit the data exactly. First, we modify the notion of the most powerful unfalsified model for the case of finite data by fixing the number of inputs and minimizing the order. Then, we give necessary and sufficient conditions for the existence and uniqueness of the most powerful unfalsified model. In this case, the true data generating system is identifiable and coincides with the most powerful unfalsified model. Finally, when the identifiability conditions are not satisfied, there are infinitely many exact models. We show that in this case the set of bounded complexity exact models is affine and every exact model is a sum of the most powerful unfalsified model and an autonomous model with bounded complexity.
</blockquote>
<p><blockquote>
Keywords: Behaviors, exact system identification, Hankel matrix, most powerful unfalsified model, persistency of excitation.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="agcd-matrix">20</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi, N.&nbsp;Guglielmi, and I.&nbsp;Markovsky.
 Generalized algorithms for the approximate matrix polynomial GCD of
  reducing data uncertainties with application to MIMO system and control.
 <em>J. Comput. Appl. Math.</em>, 393:113499, 2021.
[&nbsp;<a href="j_bib.html#agcd-matrix">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.cam.2021.113499">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1907.13101">pdf</a>&nbsp;]
<blockquote>
Computation of (approximate) polynomials common factors is an important problem in several fields of science, like control theory and signal processing. While the problem has been widely studied for scalar polynomials, the scientific literature in the framework of matrix polynomials seems to be limited to the problem of exact greatest common divisors computation. In this paper, we generalize two algorithms from scalar to matrix polynomials. The first one is fast and simple. The second one is more accurate but computationally more expensive. We test the performances of the two algorithms and observe similar behavior to the one in the scalar case. Finally we describe an application to multi-input multi-output linear time-invariant dynamical systems.
</blockquote>
<p><blockquote>
Keywords: matrix polynomials, approximate GCD, subspace method, matrix ODE
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="overview-ddctr">21</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and F.&nbsp;Dörfler.
 Behavioral systems theory in data-driven analysis, signal processing,
  and control.
 <em>Annual Reviews in Control</em>, 52:42--64, 2021.
[&nbsp;<a href="j_bib.html#overview-ddctr">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.arcontrol.2021.09.005">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/overview-ddctr.pdf">pdf</a>&nbsp;]
<blockquote>
The behavioral approach to systems theory, put forward 40 years ago by Jan C. Willems, remained till recently an esoteric niche of research. The renewed interest in the last years is because of its unique suitability for the newly emerged data-driven paradigm, specifically the representation-free perspective on dynamical systems as sets of trajectories. A result derived in the behavioral setting that became known as the fundamental lemma started a new class of subspace-type data-driven methods. The fundamental lemma gives conditions for a non-parametric representation of a linear time-invariant system by the image of a Hankel matrix constructed from raw time series data. This paper reviews the fundamental lemma, its generalizations, and related data-driven analysis, signal processing, and control methods. A prototypical signal processing problem, reviewed in the paper, is missing data estimation. It includes simulation, state estimation, and output tracking control as special cases. The direct data-driven control methods using the fundamental lemma and the non-parametric representation are loosely classified as implicit and explicit approaches. Representative examples are data-enabled predictive control (an implicit method) and data-driven linear quadratic regulation (an explicit method). These methods are equally amenable to certainty-equivalence as well as to robust control. Emphasis is put on the robustness of the methods under noise. The methods allow for theoretical certification, they are computationally tractable, in comparison with machine learning methods require small amount of data, and are robustly implementable in real-time on complex physical systems.
</blockquote>
<p><blockquote>
Keywords: Behavioral systems theory, data-driven control, missing data estimation, system identification
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="gustavo-tim">22</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Q. Carapia, I.&nbsp;Markovsky, R.&nbsp;Pintelon, P.&nbsp;Csurcsia, and D.&nbsp;Verbeke.
 Experimental validation of a data-driven step input estimation method
  for dynamic measurements.
 <em>IEEE Transactions on Instrumentation and Measurement</em>,
  69:4843--4851, 2020.
[&nbsp;<a href="j_bib.html#gustavo-tim">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TIM.2019.2951865">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/gustavo-tim.pdf">pdf</a>&nbsp;]
<blockquote>
Simultaneous fast and accurate measurement is still a challenging and active problem in metrology. A sensor is a dynamic system that produces a transient response. For fast measurements, the unknown input needs to be estimated using the sensor transient response. When a model of the sensor exists, standard compensation filter methods can be used to estimate the input. If a model is not available, either an adaptive filter is used or a sensor model is identified before the input estimation. Recently, a signal processing method was proposed to avoid the identification stage and estimate directly the value of a step input from the sensor response. This data-driven step input estimation method requires only the order of the sensor dynamics and the sensor static gain. To validate the data-driven step input estimation method, in this paper, the uncertainty of the input estimate is studied and illustrated on simulation and real-life weighing measurements. It was found that the predicted mean- squared error of the input estimate is close to an approximate Cramér-Rao lower bound for biased estimators.
</blockquote>
<p><blockquote>
Keywords: Metrology, Dynamic measurement, Cramér-Rao lower bound, Data-driven signal processing
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="gustavo-csda">23</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Q. Carapia, I.&nbsp;Markovsky, R.&nbsp;Pintelon, P.&nbsp;Csurcsia, and D.&nbsp;Verbeke.
 Bias and covariance of the least squares estimate in a structured
  errors-in-variables problem.
 <em>Comput. Statist. Data Anal.</em>, 144:106893, 2020.
[&nbsp;<a href="j_bib.html#gustavo-csda">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csda.2019.106893">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/gustavo-csda.pdf">pdf</a>&nbsp;]
<blockquote>
A structured errors-in-variables (EIV) problem arising in metrology is studied. The observations of a sensor response are subject to perturbation. The input estimation from the transient response leads to a structured EIV problem. Total least squares (TLS) is a typical estimation method to solve EIV problems. The TLS estimator of an EIV problem is consistent, and can be computed efficiently when the perturbations have zero mean, and are independently and identically distributed (i.i.d). If the perturbation is additionally Gaussian, the TLS solution coincides with maximum-likelihood (ML). However, the computational complexity of structured TLS and total ML prevents their real-time implementation. The least-squares (LS) estimator offers a suboptimal but simple recursive solution to structured EIV problems with correlation, but the statistical properties of the LS estimator are unknown. To know the LS estimate uncertainty in EIV problems, either structured or not, to provide confidence bounds for the estimation uncertainty, and to find the difference from the optimal solutions, the bias and variance of the LS estimates should be quantified. Expressions to predict the bias and variance of LS estimators applied to unstructured and structured EIV problems are derived. The predicted bias and variance quantify the statistical properties of the LS estimate and give an approximation of the uncertainty and the mean squared error for comparison to the Cramer-Rao lower bound of the structured EIV problem.
</blockquote>
<p><blockquote>
Keywords: structured errors-in-variables problems, least-squares estimation, Cramer-Rao lower bound, statistical analysis, uncertainty assessment, Monte Carlo simulation
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="gustavo-measurement">24</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Q. Carapia and I.&nbsp;Markovsky.
 Input parameters estimation from time-varying measurements.
 <em>Measurement</em>, 153:107418, 2020.
[&nbsp;<a href="j_bib.html#gustavo-measurement">bib</a>&nbsp;| 
<a href="https://doi.org/10.1016/j.measurement.2019.107418">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/gustavo-measurement.pdf">pdf</a>&nbsp;]
<blockquote>
A measurement is a dynamical process that aims to estimate the true value of a measurand. The measurand is the input that excites a sensor, and, as a consequence, the sensor output is a transient response. The main approach to estimate the input is applying the sensor transient response to another dynamical system. This dynamical system is designed by deconvolution to invert the sensor dynamics and compensate the sensor response. Digital signal processors enable an alternative approach to estimate the unknown input. There exists a data-driven subspace-based signal processing method that estimates a measurand, assuming it is constant during the measurement. To estimate the parameters of a measurand that varies at a constant rate, we extended the data-driven input estimation method to make it adaptive to the affine input. In this paper, we describe the proposed subspace signal processing method for the measurement of an affine measurand and compare its performance to a maximum-likelihood input estimation method and to an existing time-varying compensation filter. The subspace method is recursive and allows real-time implementations since it directly estimates the input without identifying a sensor model. The maximum-likelihood method is model-based and requires very high computational effort. In this form, the maximum-likelihood method cannot be implemented in real-time, however, we used it as a reference to evaluate the subspace method and the time-varying compensation filter results. The effectiveness of the subspace method is validated in a simulation study with a time-varying sensor. The results show that the subspace method estimation has relative errors that are one order of magnitude smaller and converges two times faster than the compensation filter.
</blockquote>
<p><blockquote>
Keywords: Affine input estimation, Subspace estimation method, Maximum-likelihood estimation method, Recursive least squares, Dynamic weighing
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="cd-est">25</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, T.&nbsp;Liu, and A.&nbsp;Takeda.
 Data-driven structured noise filtering via common dynamics
  estimation.
 <em>IEEE Trans. Signal Process.</em>, 68:3064--3073, 2020.
[&nbsp;<a href="j_bib.html#cd-est">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TSP.2020.2993676">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/cd-est.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/common-dynamics.tar">software</a>&nbsp;]
<blockquote>
Classical signal from noise separation problems assume that the signal is a trajectory of a low-complexity linear time-invariant system and that the noise is a random process. In this paper, we generalize this classical setup to what we call data-driven structured noise filtering. In the new setup, the noise has two components: structured noise, which is also a trajectory of a low-complexity linear time-invariant system, and unstructured noise, which is a zero-mean white Gaussian process. The key assumption that makes the separation problem in the new setup well posed is that among several experiments, the signal's dynamics remains the same while the structured noise's dynamics varies. The data-driven structured noise filtering problem then becomes a problem of estimation of common linear time-invariant dynamics among several observed signals. We show that this latter problem is a structured low-rank approximation problem with multiple rank constraints and use a subspace identification approach for solving it. The resulting methods allow computationally efficient and numerically robust implementation and have the system theoretic interpretation of finding the intersection of autonomous linear time-invariant behaviors. Statistical analysis of the methods providing confidence bounds is a topic for future research.
</blockquote>
<p><blockquote>
Keywords: Hankel structured low-rank approximation, Subspace system identification, Behavioral approach
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ddctr-test">26</a>]
</td>
<td class="bibtexitem">
V.&nbsp;Mishra, I.&nbsp;Markovsky, and B.&nbsp;Grossmann.
 Data-driven tests for controllability.
 <em>Control Systems Letters</em>, 5:517--522, 2020.
[&nbsp;<a href="j_bib.html#ddctr-test">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/LCSYS.2020.3003770">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/ddctr-test.pdf">pdf</a>&nbsp;]
<blockquote>
The fundamental lemma due to Willems et al. plays an important role in system identification and data-driven control. One of the assumptions for the fundamental lemma is that the underlying linear time-invariant system is controllable. In this paper, the fundamental lemma is extended to address system identification for uncontrollable systems. Then, a data-driven algebraic test is derived to check whether the underlying system is controllable or not. An algorithm based on the singular value decomposition of a Hankel matrix constructed from the data is provided to implement the developed test. The algorithm has cubic computational cost. Examples are given to illustrate the theoretical results.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="cd-est-simax">27</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Liu, I.&nbsp;Markovsky, T.-K. Pong, and A.&nbsp;Takeda.
 A hybrid penalty method for a class of optimization problems with
  multiple rank constraints.
 <em>SIAM J. Matrix Anal. Appl.</em>, 41:1260--1283, 2020.
[&nbsp;<a href="j_bib.html#cd-est-simax">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/19M1269919">DOI</a>&nbsp;| 
<a href="https://arxiv.org/pdf/1906.10396">pdf</a>&nbsp;]
<blockquote>
In this paper, we consider the problem of minimizing a smooth objective over multiple rank constraints on Hankel-structured matrices. This kind of problems arises in system identification, system theory and signal processing, where the rank constraints are typically “hard constraints”. To solve these problems, we propose a hybrid penalty method that combines a penalty method with a post-processing scheme. Specifically, we solve the penalty subproblems until the penalty parameter reaches a given threshold, and then switch to a local alternating “pseudo-projection” method to further reduce constraint violation. Pseudo-projection is a generalization of the concept of projection. We show that a pseudo-projection onto a single low-rank Hankel-structured matrix constraint can be computed efficiently by existing softwares such as SLRA (Markovsky and Usevich, 2014), under mild assumptions. We also demonstrate how the penalty subproblems in the hybrid penalty method can be solved by pseudo-projection-based optimization methods, and then present some convergence results for our hybrid penalty method. Finally, the efficiency of our method is illustrated by numerical examples.
</blockquote>
<p><blockquote>
Keywords: Hankel-structure, system identification, hybrid penalty method, pseudo-projection.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="miaomiao">28</a>]
</td>
<td class="bibtexitem">
M.&nbsp;Zhang, I.&nbsp;Markovsky, C.&nbsp;Schretter, and J.&nbsp;D'hooge.
 Compressed ultrasound signal reconstruction using a low-rank and
  joint-sparse representation model.
 <em>Transactions on Ultrasonics, Ferroelectrics, and Frequency
  Control</em>, 66:1232--1245, 2019.
[&nbsp;<a href="j_bib.html#miaomiao">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TUFFC.2019.2915096">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/miaomiao.pdf">pdf</a>&nbsp;]
<blockquote>
With the introduction of very dense sensor arrays in ultrasound imaging, data transfer rate and data storage can become a bottle neck in ultrasound system design. To reduce the amount of sampled channel data, we proposed a new approach based on the low-rank and joint-sparse model that allows to explore the correlations between different ultrasound channels and transmissions. With this method, the minimum number of measurements at each channel can be lower than the sparsity in compressive sensing theory. The accuracy of reconstruction is less dependent on the sparse basis. An optimization algorithm, based on simultaneous direction method of multipliers, is proposed to efficiently solve the resulting optimization problem. Results on different datasets with different experimental settings show that the proposed method is better adapted to the ultrasound signals and can recover the image with fewer samples (e.g. 10% of the samples), while maintaining adequate image quality.
</blockquote>
<p><blockquote>
Keywords: compressive sensing, matrix completion, low-rank and joint-sparse model, ultrasound imaging
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="aut-wiener">29</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 On the behavior of autonomous Wiener systems.
 <em>Automatica</em>, 110:108601, 2019.
[&nbsp;<a href="j_bib.html#aut-wiener">bib</a>&nbsp;| 
<a href="https://doi.org/10.1016/j.automatica.2019.108601">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/aut-wiener.pdf">pdf</a>&nbsp;]
<blockquote>
Wiener systems are nonlinear dynamical systems, consisting of a linear dynamical system and a static nonlinear system in a series connection. Existing results for analysis and identification of Wiener systems assume zero initial conditions. In this paper, we consider the response of a Wiener system to initial conditions only, i.e., we consider autonomous Wiener systems. Our main result is a proof that an autonomous Wiener system with a polynomial nonlinearity is equivalent to a finite-dimensional linear system. The order of the equivalent linear system is (<em>n</em> + <em>d</em>)-choose-<em>d</em> --- the number of combinations with repetitions of <em>d</em> elements out of <em>n</em> elements --- where <em>n</em> is the order of the linear subsystem and <em>d</em> is the degree of the nonlinearity. The relation between the eigenvalues of the equivalent linear system and the linear subsystem is given by a rank-1 factorization of a symmetric <I>d</I>-way tensor. As an application of the result, we outline a procedure for identification of autonomous Wiener systems.
</blockquote>
<p><blockquote>
Keywords: Nonlinear system identification, Block-oriented models, Wiener system
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="agcd-ode">30</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Fazzi, N.&nbsp;Guglielmi, and I.&nbsp;Markovsky.
 An ODE based method for computing the approximate greatest common
  divisor of polynomials.
 <em>Numerical algorithms</em>, 81:719--740, 2018.
[&nbsp;<a href="j_bib.html#agcd-ode">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s11075-018-0569-0">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/agcd-ode.pdf">pdf</a>&nbsp;]
<blockquote>
Computing the greatest common divisor of a set of polynomials is a problem which plays an important role in different fields, such as linear system, control and network theory. In practice, the polynomials are obtained through measurements and computations, so that their coefficients are inexact. This poses the problem of computing an approximate common factor. We propose an improvement and a generalization of the method recently proposed in Guglielmi, N., Markovsky, I.: An ODE based method for computing the distance of coprime polynomials. SIAM J. Numer. Anal. 55, 1456–1482 (2017), which restates the problem as a (structured) distance to singularity of the Sylvester matrix. We generalize the algorithm in order to work with more than 2 polynomials and to compute an Approximate GCD (Greatest Common Divisor) of degree k &gt; 0; moreover we show that the algorithm becomes faster by replacing the eigenvalues by the singular values.
</blockquote>
<p><blockquote>
Keywords: Sylvester matrix, iterative methods, Approximate GCD, polynomials
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-agcd">31</a>]
</td>
<td class="bibtexitem">
K.&nbsp;Usevich and I.&nbsp;Markovsky.
 Variable projection methods for approximate (greatest) common divisor
  computations.
 <em>Theoretical Computer Science</em>, 681:176--198, 2017.
[&nbsp;<a href="j_bib.html#slra-agcd">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.tcs.2017.03.028">DOI</a>&nbsp;| 
<a href="http://arxiv.org/pdf/1304.6962v1">pdf</a>&nbsp;]
<blockquote>
We consider the problem of finding for a given <em>N</em>-tuple of polynomials the closest <em>N</em>-tuple that has a common divisor of degree at least <em>d</em>. Extended weighted Euclidean semi-norm of coefficients is used as a measure of closeness. Two equivalent formulations of the problem are considered: (i) direct optimization over common divisors and cofactors, and (ii) Sylvester lowrank approximation. We use the duality between least-squares and least-norm problems to show that (i) and (ii) are closely related to mosaic Hankel low-rank approximation. This allows us to apply recent results on complexity and accuracy of computations for mosaic Hankel low-rank approximation. We develop optimization methods based on the variable projection principle. These methods have linear complexity in the degrees of the polynomials if either <em>d</em> is small or <em>d</em> is of the same order as the degrees of the polynomials. We provide a software implementation that is based on a software package for structured low-rank approximation.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ddsp">32</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 A missing data approach to data-driven filtering and control.
 <em>IEEE Trans. Automat. Contr.</em>, 62:1972--1978, 2017.
[&nbsp;<a href="j_bib.html#ddsp">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2016.2591178">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/ddsp.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/ddsp.tar">software</a>&nbsp;]
<blockquote>
In signal processing as well as in control and other mathematical engineering areas, it is common to use a model-based approach, which splits the problem into two steps: 1) model identification and 2) model-based design. Despite its success the model-based approach has the shortcoming that the design objective is not taken into account at the identification step, i.e., the model is not optimized for its intended use. In this paper, we propose an approach for data processing, called data-driven signal processing, that combines the identification and the model-based design into one joint problem. The to-be-computed signal is modeled as a missing part of a trajectory of the (unknown) data generating system. Subsequently, the missing data estimation problem is reformulated as a mosaic-Hankel structured matrix low-rank approximation and completion problem. A local optimization methods, based on the variable projections principle, is used for the numerical solution of the matrix completion/approximation problem. The missing data estimation approach for data-driven signal processing and the local optimization method for its implementation in practice are illustrated on examples of state estimation, filtering/smoothing, and prediction. Development of fast algorithms with provable properties in the presence of measurement noise and disturbances will make the matrix completion approach for data-driven signal processing a practically feasible alternative to the model-based methods.
</blockquote>
<p><blockquote>
Keywords: data-driven, Kalman filtering, structured low-rank approximation, missing data, matrix completion.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="pk">33</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and G.&nbsp;Mercère.
 Subspace identification with constraints on the impulse response.
 <em>Int. J. Contr.</em>, 90:1728--1735, 2017.
[&nbsp;<a href="j_bib.html#pk">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/00207179.2016.1219922">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/ijc-rev.pdf">pdf</a>&nbsp;| 
<a href="https://codeocean.com/2017/10/12/system-identification-with-prior-knowledge-on-the-impulse-response/code">software</a>&nbsp;]
<blockquote>
Subspace identification methods may produce unreliable model estimates when a small number of noisy measurements are available. In such cases, the accuracy of the estimated parameters can be improved by using prior knowledge about the system. The prior knowledge considered in this paper is constraints on the impulse response. It is motivated by availability of information about the steady-state gain, overshoot, and rise time of the system, which in turn can be expressed as constraints on the impulse response. The method proposed has two steps: 1) estimation of the impulse response with linear equality and inequality constraints, and 2) realization of the estimated impulse response. The problem on step 1 is shown to be a convex quadratic programming problem. In the case of prior knowledge expressed as equality constraints, the problem on step 1 admits a closed form solution. In the general case of equality and inequality constraints, the solution is computed by standard numerical optimization methods. We illustrate the performance of the method on a mass-spring-damper system.
</blockquote>
<p><blockquote>
Keywords: system identification, subspace methods, prior knowledge, behavioral approach.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="dist-uncontr">34</a>]
</td>
<td class="bibtexitem">
N.&nbsp;Guglielmi and I.&nbsp;Markovsky.
 An ODE based method for computing the distance of co-prime
  polynomials to common divisibility.
 <em>SIAM Journal on Numerical Analysis</em>, 55:1456--1482, 2017.
[&nbsp;<a href="j_bib.html#dist-uncontr">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/15M1018265">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/dist-unctr.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/dist_unctr.tar">software</a>&nbsp;]
<blockquote>
The problem of computing the distance of two real coprime polynomials to the set of polynomials with a nontrivial greatest common divisor (GCD) appears in computer algebra, signal processing, and control theory. It has been studied in the literature under the names approximate common divisor, -GCD, and distance to uncontrollability. Existing solution methods use different types of local optimization methods and require a user defined initial approximation. In this paper, we propose a new method that allows us to include constraints on the coefficients of the polynomials. Moreover, the method proposed in the paper is more robust to the initial approximation than Newton-type optimization methods available in the literature. Our approach consists of two steps: 1) reformulate the problem as the problem of determining the structured distance to singularity of an associated Sylvester matrix, and 2) integrate a system of ordinary differential equations, which describes the gradient associated to the functional to be minimized.
</blockquote>
<p><blockquote>
Keywords: GCD, Sylvester matrix, structured pseudospectrum, structured low-rank approximation, ODEs on matrix manifolds, structured distance to singularity.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="als-kdu">35</a>]
</td>
<td class="bibtexitem">
K.&nbsp;Usevich and I.&nbsp;Markovsky.
 Adjusted least squares fitting of algebraic hypersurfaces.
 <em>Linear Algebra Appl.</em>, 502:243--274, 2016.
[&nbsp;<a href="j_bib.html#als-kdu">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.laa.2015.07.023">DOI</a>&nbsp;| 
<a href="http://arxiv.org/abs/1412.2291">pdf</a>&nbsp;]
<blockquote>
We consider the problem of fitting a set of points in Euclidean space by an algebraic hypersurface. We assume that points on a true hypersurface, described by a polynomial equation, are corrupted by zero mean independent Gaussian noise, and we estimate the coefficients of the true polynomial equation. The adjusted least squares estimator accounts for the bias present in the ordinary least squares estimator. The adjusted least squares estimator is based on constructing a quasi-Hankel matrix, which is a bias-corrected matrix of moments. For the case of unknown noise variance, the estimator is defined as a solution of a polynomial eigenvalue problem. In this paper, we present new results on invariance properties of the adjusted least squares estimator and an improved algorithm for computing the estimator for an arbitrary set of monomials in the polynomial equation.
</blockquote>
<p><blockquote>
Keywords: hypersurface fitting; curve fitting; statistical estimation, errors-in-variables; Quasi-Hankel matrix; Hermite polynomials; affine invariance; subspace clustering
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jan">36</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 On the most powerful unfalsified model for data with missing values.
 <em>Systems &amp; Control Lett.</em>, 95:53--61, 2016.
[&nbsp;<a href="j_bib.html#jan">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.sysconle.2015.12.012">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/jan.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/mpum-md.tar">software</a>&nbsp;]
<blockquote>
The notion of the most powerful unfalsified model plays a key role in system identification. Since its introduction in the mid 80's, many methods have been developed for its numerical computation. All currently existing methods, however, assume that the given data is a /complete/ trajectory of the system. Motivated by the practical issues of data corruption due to failing sensors, transmission lines, or storage devices, we study the problem of computing the most powerful unfalsified model from data with missing values. We do not make assumptions about the nature or pattern of the missing values apart from the basic one that they are a part of a trajectory of a linear time-invariant system. The identification problem with missing data is equivalent to a Hankel structured low-rank matrix completion problem. The method proposed constructs rank deficient complete submatrices of the incomplete Hankel matrix. Under specified conditions the kernels of the submatrices form a nonminimal kernel representation of the data generating system. The final step of the algorithm is reduction of the nonminimal kernel representation to a minimal one. Apart from its practical relevance in identification, missing data is a useful concept in systems and control. Classic problems, such as simulation, filtering, and tracking control can be viewed as missing data estimation problems for a given system. The corresponding identification problems with missing data are &ldquo;data-driven&rdquo; equivalents of the classical simulation, filtering, and tracking control problems.
</blockquote>
<p><blockquote>
Keywords: most powerful unfalsified model, exact system identification, subspace methods, missing data, low-rank matrix completion.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sensor-ieee">37</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Comparison of adaptive and model-free methods for dynamic
  measurement.
 <em>IEEE Signal Proc. Lett.</em>, 22(8):1094--1097, 2015.
[&nbsp;<a href="j_bib.html#sensor-ieee">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/LSP.2014.2388369">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/sensor-ieee.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/sensor-ieee-code.tar">software</a>&nbsp;]
<blockquote>
Dynamic measurement aims to improve the speed and accuracy characteristics of measurement devices by signal processing. State-of-the-art dynamic measurement methods are model-based adaptive methods, i.e., 1) they estimate model parameters in real-time and 2) based on the identified model perform model-based signal processing. The proposed model-free method belongs to the class of the subspace identification methods. It computes directly the quantity of interest without an explicit parameter estimation. This allows efficient computation as well as applicability to general high order multivariable processes.
</blockquote>
<p><blockquote>
Keywords: subspace methods, total least squares, adaptive filtering, model-free signal processing.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-consistency">38</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and R.&nbsp;Pintelon.
 Identification of linear time-invariant systems from multiple
  experiments.
 <em>IEEE Trans. Signal Process.</em>, 63(13):3549--3554, 2015.
[&nbsp;<a href="j_bib.html#slra-consistency">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TSP.2015.2428218">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/papers/slra-consistency.pdf">pdf</a>&nbsp;]
<blockquote>
A standard assumption for consistent estimation in the errors-in-variables setting is persistency of excitation of the noise free input signal. We relax this assumption by considering data from multiple experiments. Consistency is obtained asymptotically as the number of experiments tends to infinity. The main theoretical and algorithmic difficulties are related to the growing number of to-be-estimated initial conditions. The method proposed in the paper is based on analytic elimination of the initial conditions and optimization over the remaining parameters. The resulting estimator is consistent, however, achieving asymptotically efficiency remains an open problem.
</blockquote>
<p><blockquote>
Keywords: maximum likelihood system identification, sum-of-damped exponentials modeling, consistency, structured low-rank approximation
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sensor-cep">39</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 An application of system identification in metrology.
 <em>Control Eng. Practice</em>, 43:85--93, 2015.
[&nbsp;<a href="j_bib.html#sensor-cep">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.conengprac.2015.07.001">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/sensor-cep.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/sensor-cep-experiments.html">software</a>&nbsp;]
<blockquote>
Dynamic measurement refers to problems in metrology aiming at modification of characteristics of measurement devices by signal processing. Prototypical dynamic measurement problems, used in the paper as illustrative examples, are speeding up thermometers and weight scales. The paper presents a system theoretic formalization of the dynamic measurement problem as an input estimation problem for a system with step input. If the process dynamics is a priori known, the dynamic measurement problem is equivalent to a state estimation problem and can be solved efficiently in the linear time-invariant case by the Kalman filter. In the case of unknown process dynamics, the dynamic measurement problem can be solved by adaptive filtering methods. A topic of current research, called data-driven dynamic measurement, is development of methods that compute the measurement quantity without explicitly identifying the process dynamics.
</blockquote>
<p><blockquote>
Keywords: system identification, behavioral approach, Kalman filtering, metrology, reproducible research
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-efficient">40</a>]
</td>
<td class="bibtexitem">
K.&nbsp;Usevich and I.&nbsp;Markovsky.
 Variable projection for affinely structured low-rank approximation in
  weighted 2-norms.
 <em>J. Comput. Appl. Math.</em>, 272:430--448, 2014.
[&nbsp;<a href="j_bib.html#slra-efficient">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.cam.2013.04.034">DOI</a>&nbsp;| 
<a href="http://arxiv.org/pdf/1211.3938v2">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
The structured low-rank approximation problem for general affine structures, weighted 2-norms and fixed elements is considered. The variable projection principle is used to reduce the dimensionality of the optimization problem. Algorithms for evaluation of the cost function, the gradient and an approximation of the Hessian are developed. For <em>m</em>&#215;<em>n</em> mosaic Hankel matrices the algorithms have complexity <em>O</em>(<em>m</em><sup>2</sup><em>n</em>).
</blockquote>
<p><blockquote>
Keywords: Structured low-rank approximation; Variable projection; Mosaic Hankel matrices; Weighted 2-norm; Fixed elements; Computational complexity
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-software">41</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and K.&nbsp;Usevich.
 Software for weighted structured low-rank approximation.
 <em>J. Comput. Appl. Math.</em>, 256:278--292, 2014.
[&nbsp;<a href="j_bib.html#slra-software">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.cam.2013.07.048">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/slra.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
A software package is presented that computes locally optimal solutions to low-rank approximation problems with the following features:
<p><ul>
<em>mosaic Hankel structure</em> constraint on the approximating matrix,
<em>weighted 2-norm</em> approximation criterion,
<em>fixed elements</em> in the approximating matrix,
<em>missing elements</em> in the data matrix, and
<em>linear constraints</em> on an approximating matrix's left kernel basis.
</ul>
It implements a variable projection type algorithm and allows the user to choose standard local optimization methods for the solution of the parameter optimization problem. For an <em>m</em>&#215;<em>n</em> data matrix, with <em>n</em>&gt;<em>m</em>, the computational complexity of the cost function and derivative evaluation is&nbsp;<em>O</em>(<em>m</em><sup>2</sup><em>n</em>). The package is suitable for applications with <em>n</em><em>m</em>. In statistical estimation and data modeling---the main application areas of the package---<em>n</em><em>m</em> corresponds to modeling of large amount of data by a low-complexity model. Performance results on benchmark system identification problems from the database DAISY and approximate common divisor problems are presented.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="overview">42</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Recent progress on variable projection methods for structured
  low-rank approximation.
 <em>Signal Processing</em>, 96PB:406--419, 2014.
[&nbsp;<a href="j_bib.html#overview">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.sigpro.2013.09.021">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/overview.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
Rank deficiency of a data matrix is equivalent to the existence of an exact linear model for the data. For the purpose of linear static modeling, the matrix is unstructured and the corresponding modeling problem is an approximation of the matrix by another matrix of a lower rank. In the context of linear time-invariant dynamic models, the appropriate data matrix is Hankel and the corresponding modeling problems becomes structured low-rank approximation. Low-rank approximation has applications in: system identification; signal processing, machine learning, and computer algebra, where different types of structure and constraints occur. This paper gives an overview of recent progress in efficient local optimization algorithms for solving weighted mosaic-Hankel structured low-rank approximation problems. In addition, the data matrix may have missing elements and elements may be specified as exact. The described algorithms are implemented in a publicly available software package. Their application to system identification, approximate common divisor, and data-driven simulation problems is described in this paper and is illustrated by reproducible simulation examples. As a data modeling paradigm the low-rank approximation setting is closely related to the the behavioral approach in systems and control, total least squares, errors-in-variables modeling, principal component analysis, and rank minimization.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="UM12-aut">43</a>]
</td>
<td class="bibtexitem">
K.&nbsp;Usevich and I.&nbsp;Markovsky.
 Optimization on a Grassmann manifold with application to system
  identification.
 <em>Automatica</em>, 50:1656--1662, 2014.
[&nbsp;<a href="j_bib.html#UM12-aut">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2014.04.010">DOI</a>&nbsp;| 
<a href="http://www.gipsa-lab.grenoble-inp.fr/~konstantin.usevich/_preprints/Usevich.Markovsky14A-Optimization.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
In this paper, we consider the problem of optimization of a cost function on a Grassmann manifold. This problem appears in system identification in the behavioral setting, which is a structured low-rank approximation problem. We develop a new method for local optimization on the Grassmann manifold with switching coordinate charts. This method reduces the optimization problem on the manifold to an optimization problem in a bounded domain of an Euclidean space. Our experiments show that this method is competitive with state- of-the-art retraction-based methods. Compared to retraction-based methods, the proposed method allows to incorporate easily an arbitrary optimization method for solving the optimization subproblem in the Euclidean space.
</blockquote>
<p><blockquote>
Keywords: system identification, over-parameterized models, Grassmann manifold, coordinate charts, structured low-rank approximation, optimization
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="pltv">44</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, J.&nbsp;Goos, K.&nbsp;Usevich, and R.&nbsp;Pintelon.
 Realization and identification of autonomous linear periodically
  time-varying systems.
 <em>Automatica</em>, 50:1632--1640, 2014.
[&nbsp;<a href="j_bib.html#pltv">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2014.04.003">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/pltv-rev3.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/pltv-code.tgz">software</a>&nbsp;]
<blockquote>
Subsampling of a linear periodically time-varying system results in a collection of linear time-invariant systems with common poles. This key fact, known as &ldquo;lifting&rdquo;, is used in a two step realization method. The first step is the realization of the time-invariant dynamics (the lifted system). Computationally, this step is a rank-revealing factorization of a block-Hankel matrix. The second step derives a state space representation of the periodic time-varying system. It is shown that no extra computations are required in the second step. The computational complexity of the overall method is therefore equal to the complexity for the realization of the lifted system. A modification of the realization method is proposed, which makes the complexity independent of the parameter variation period. Replacing the rank-revealing factorization in the realization algorithm by structured low-rank approximation yields a maximum likelihood identification method. Existing methods for structured low-rank approximation are used to identify efficiently linear periodically time-varying system. These methods can deal with missing data.

</blockquote>
<p><blockquote>
Keywords: linear periodically time-varying systems, lifting, realization, Kung's algorithm, Hankel low-rank approximation, maximum likelihood estimation.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="rslra">45</a>]
</td>
<td class="bibtexitem">
M.&nbsp;Ishteva, K.&nbsp;Usevich, and I.&nbsp;Markovsky.
 Factorization approach to structured low-rank approximation with
  applications.
 <em>SIAM J. Matrix Anal. Appl.</em>, 35(3):1180--1204, 2014.
[&nbsp;<a href="j_bib.html#rslra">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/130931655">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/rslra.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
We consider the problem of approximating an affinely structured matrix, for example a Hankel matrix, by a low-rank matrix with the same structure. This problem occurs in system identification, signal processing and computer algebra, among others. We impose the low-rank by modeling the approximation as a product of two factors with reduced dimension. The structure of the low-rank model is enforced by introducing a regularization term in the objective function. The proposed local optimization algorithm is able to solve the weighted structured low-rank approximation problem, as well as to deal with the cases of missing or fixed elements. In contrast to approaches based on kernel representations (in linear algebraic sense), the proposed algorithm is designed to address the case of small targeted rank. We compare it to existing approaches on numerical examples of system identification, approximate greatest common divisor problem, and symmetric tensor decomposition and demonstrate its consistently good performance.
</blockquote>
<p><blockquote>
Keywords: low-rank approximation, affine structure, regularization, system identification, approximate greatest common divisor
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="rgtls">46</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Rhode, K.&nbsp;Usevich, I.&nbsp;Markovsky, and F.&nbsp;Gauterin.
 A recursive restricted total least-squares algorithm.
 <em>IEEE Trans. Signal Process.</em>, 62(21):5652--5662, 2014.
[&nbsp;<a href="j_bib.html#rgtls">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TSP.2014.2350959">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/rgtls.pdf">pdf</a>&nbsp;| 
<a href="http://ieeexplore.ieee.org/xpl/abstractMultimedia.jsp?arnumber=6882213">software</a>&nbsp;]
<blockquote>
We show that the generalized total least squares problem with a singular noise covariance matrix is equivalent to the restricted total least squares problem and propose a recursive method for its numerical solution. The method is based on the generalized inverse iteration. The estimation error covariance matrix and the estimated augmented correction are also characterized and computed recursively. The algorithm is cheap to compute and is suitable for online implementation. Simulation results in least squares, data least squares, total least squares, and restricted total least squares noise scenarios show fast convergence of the parameter estimates to their optimal values obtained by corresponding batch algorithms.
</blockquote>
<p><blockquote>
Keywords: total least squares, generalized total least squares, restricted total least squares (RTLS), recursive estimation, subspace tracking, system identification
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-ext">47</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and K.&nbsp;Usevich.
 Structured low-rank approximation with missing data.
 <em>SIAM J. Matrix Anal. Appl.</em>, 34(2):814--830, 2013.
[&nbsp;<a href="j_bib.html#slra-ext">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/120883050">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/slra-ext.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
We consider low-rank approximation of affinely structured matrices with missing elements. The method proposed is based on reformulation of the problem as inner and outer optimization. The inner minimization is a singular linear least-norm problem and admits an analytic solution. The outer problem is a nonlinear least squares problem and is solved by local optimization methods: minimization subject to quadratic equality constraints and unconstrained minimization with regularized cost function. The method is generalized to weighted low-rank approximation with missing values and is illustrated on approximate low-rank matrix completion, system identification, and data-driven simulation problems. An extended version of the paper is a literate program, implementing the method and reproducing the presented results.
</blockquote>
<p><blockquote>
Keywords: low-rank approximation, missing data, variable projection, system identification, approximate matrix completion.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ident">48</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 A software package for system identification in the behavioral
  setting.
 <em>Control Eng. Practice</em>, 21:1422--1436, 2013.
[&nbsp;<a href="j_bib.html#ident">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.conengprac.2013.06.010">DOI</a>&nbsp;| 
<a href="https://imarkovs.github.io/publications/ident.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-ident.html">software</a>&nbsp;]
<blockquote>
An identification problem with no a priori separation of the variables into inputs and outputs and representation invariant approximation criterion is considered. The model class consists of linear time-invariant systems of bounded complexity and the approximation criterion is the minimum of a weighted 2-norm distance between the given time series and a time series that is consistent with the model. The problem is equivalent to and is solved as a mosaic-Hankel structured low-rank approximation problem. Software implementing the approach is developed and tested on benchmark problems. Additional nonstandard features of the software are specification of exact and missing variables and identification from multiple experiments.
</blockquote>
<p><blockquote>
Keywords: system identification; model reduction; behavioral approach; missing data; low-rank approximation; total least squares; reproducible research; DAISY.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="LMFR12">49</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Le, I.&nbsp;Markovsky, C.&nbsp;Freeman, and E.&nbsp;Rogers.
 Recursive identification of Hammerstein systems with application to
  electrically stimulated muscle.
 <em>Control Eng. Practice</em>, 20(4):386--396, 2012.
[&nbsp;<a href="j_bib.html#LMFR12">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.conengprac.2011.08.001">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/271583/1/zoe2-published.pdf">pdf</a>&nbsp;]
<blockquote>
Two methods for recursive identification of Hammerstein systems are presented. In the first method, recursive least squares algorithm is applied to an overparameterized representation of the Hammerstein model and a rank-1 approximation is used to recover the linear and nonlinear parameters from the estimated overparameterized representation. In the second method, the linear and nonlinear parameters are recursively estimated in an alternate manner. Numerical example with simulated data and experimental data from human muscles show the superiority of second method.
</blockquote>
<p><blockquote>
Keywords: recursive identification; Hammerstein system; muscle model; functional electrical stimulation.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="complex-ls">50</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 On the complex least squares problem with constrained phase.
 <em>SIAM J. Matrix Anal. Appl.</em>, 32(3):987--992, 2011.
[&nbsp;<a href="j_bib.html#complex-ls">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/110826497">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/272534/1/complex-ls.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/272534/5/complex-ls-code.tar">software</a>&nbsp;]
<blockquote>
The problem of solving approximately in the least squares sense an overdetermined linear system of equations with complex valued coefficients is considered, where the elements of the solution vector are constrained to have the same phase. A direct solution to this problem is given in [Linear Algebra and Its Applications, Vol. 433, pp.&nbsp;1719--1721]. An alternative direct solution that reduces the problem to a generalized eigenvalue problem is derived in this paper. The new solution is related to generalized low-rank matrix approximation and makes possible one to use existing robust and efficient algorithms.
</blockquote>
<p><blockquote>
Keywords: Linear system of equations, Phase constraint, Low-rank approximation, Total least squares.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="M08b">51</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Closed-loop data-driven simulation.
 <em>Int. J. Contr.</em>, 83(10):2134--2139, 2010.
[&nbsp;<a href="j_bib.html#M08b">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/00207179.2010.508093">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/266868/1/unfalsified_control_rev3.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/266868/5/test_cdds.m">software</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/266868/">http</a>&nbsp;]
<blockquote>
Closed-loop data-driven simulation refers to the problem of finding the set of all responses of a closed-loop system to a given reference signal directly from an input/output trajectory of the plant and a representation of the controller. Conditions under which the problem has a solution are given and an algorithm for computing the solution is presented. The problem formulation and its solution are in the spirit of the deterministic subspace identification algorithms, i.e., in the theoretical analysis of the method, the data is assumed exact (noise free). The results have applications in data-driven control, e.g., testing controller's performance directly from closed-loop data of the plant in feedback with possibly different controller.
</blockquote>
<p><blockquote>
Keywords: System identification; Subspace methods; Persistency of excitation; Data-driven simulation and control.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MSV09">52</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, D.&nbsp;Sima, and S.&nbsp;Van Huffel.
 Total least squares methods.
 <em>Wiley Interdisciplinary Reviews: Comput. Stat.</em>, 2(2):212--217,
  2010.
[&nbsp;<a href="j_bib.html#MSV09">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1002/wics.65">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/267223/1/tls-review-published.pdf">pdf</a>&nbsp;]
<blockquote>
Recent advances in total least squares approaches for solving various errors-in-variables modeling problems are reviewed, with emphasis on the following generalizations: 1) the use of weighted norms as a measure of the data perturbation size, capturing prior knowledge about uncertainty in the data; 2) the addition of constraints on the perturbation to preserve the structure of the data matrix, motivated by structured data matrices occurring in signal and image processing, systems and control, and computer algebra; 3) the use of regularization in the problem formulation, aiming at stabilizing the solution by decreasing the effect due to intrinsic ill-conditioning of certain problems.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="LMFR08">53</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Le, I.&nbsp;Markovsky, C.&nbsp;Freeman, and E.&nbsp;Rogers.
 Identification of electrically stimulated muscle models of stroke
  patients.
 <em>Control Eng. Practice</em>, 18(4):396--407, 2010.
[&nbsp;<a href="j_bib.html#LMFR08">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.conengprac.2009.12.007">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/268388/1/cepzoe.pdf">pdf</a>&nbsp;]
<blockquote>
Despite significant recent interest in the identification of electrically stimulated muscle models, current methods are based on underlying models and identification techniques that make them unsuitable for use with subjects with incomplete paralysis. One consequence of this is that very few model-based controllers have been used in clinical trials. Motivated by one case where a model-based controller has been applied to the upper limb of stroke patients, and the modeling limitations that were encountered, this paper first undertakes a review of existing modeling techniques with particular emphasis on their limitations. A Hammerstein structure, already known in this area, is then selected, and a suitable identification procedure and set of excitation inputs are developed to address these short-comings. The technique that is proposed to obtain the model parameters from measured data is a combination of two iterative schemes: the first of these has rapid convergence and is based on alternating least squares, and the second is a more complex method to further improve accuracy. Finally, experimental results are used to assess the efficacy of the overall approach.
</blockquote>
<p><blockquote>
Keywords: System identification; Hammerstein system; Muscle models; Alternating least squares; Functional electrical
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="M10">54</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Bibliography on total least squares and related methods.
 <em>Statistics and Its Interface</em>, 3:329--334, 2010.
[&nbsp;<a href="j_bib.html#M10">bib</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/271040/1/tls-bib.pdf">pdf</a>&nbsp;]
<blockquote>
The class of total least squares methods has been growing since the basic total least squares method was proposed by Golub and Van Loan in the 70's. Efficient and robust computational algorithms were developed and properties of the resulting estimators were established in the errors-in-variables setting. At the same time the developed methods were applied in diverse areas, leading to broad literature on the subject. This paper collects the main references and guides the reader in finding details about the total least squares methods and their applications. In addition, the paper comments on similarities and differences between the total least squares and the singular spectrum analysis methods.
</blockquote>
<p><blockquote>
Keywords: total least squares, errors-in-variables, singular spectrum analysis
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MM08">55</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and S.&nbsp;Mahmoodi.
 Least-squares contour alignment.
 <em>IEEE Signal Proc. Letters</em>, 16(1):41--44, 2009.
[&nbsp;<a href="j_bib.html#MM08">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/LSP.2008.2008588">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/266829/2/dist.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/266829/1/dist.tgz">software</a>&nbsp;]
<blockquote>
The contour alignment problem, considered in this paper, is to compute the minimal distance in a least squares sense, between two explicitly represented contours, specified by corresponding points, after arbitrary rotation, scaling, and translation of one of the contours. This is a constrained nonlinear optimization problem with respect to the translation, rotation and scaling parameters, however, it is transformed into an equivalent linear least squares problem by a nonlinear change of variables. Therefore, a global solution of the contour alignment problem can be computed efficiently. It is shown that a normalized minimum value of the cost function is invariant to ordering and affine transformation of the contours and can be used as a measure for the distance between the contours. A solution is proposed to the problem of finding a point correspondence between the contours.
</blockquote>
<p><blockquote>
Keywords: Contour alignment, image registration, translation, rotation, scaling, affine invariance, least squares.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MR07">56</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and P.&nbsp;Rapisarda.
 Data-driven simulation and control.
 <em>Int. J. Contr.</em>, 81(12):1946--1959, 2008.
[&nbsp;<a href="j_bib.html#MR07">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/00207170801942170">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263423/1/ddctr.pdf">pdf</a>&nbsp;]
<blockquote>
Classical linear time-invariant system simulation methods are based on a transfer function, impulse response, or input/state/output representation. We present a method for computing the response of a system to a given input and initial conditions directly from a trajectory of the system, without explicitly identifying the system from the data. Similarly to the classical approach for simulation, the classical approach for control is model-based: first a model representation is derived from given data of the plant and then a control law is synthesised using the model and the control specifications. We present an approach for computing a linear quadratic tracking control signal that circumvents the identification step. The results are derived assuming exact data and the simulated response or control input is constructed off-line.
</blockquote>
<p><blockquote>
Keywords: simulation, data-driven control, output matching, linear quadratic tracking, system identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="M07">57</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Structured low-rank approximation and its applications.
 <em>Automatica</em>, 44(4):891--909, 2008.
[&nbsp;<a href="j_bib.html#M07">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2007.09.011">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263379/2/slra_published.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/">software</a>&nbsp;]
<blockquote>
Fitting data by a bounded complexity linear model is equivalent to low-rank approximation of a matrix constructed from the data. The data matrix being Hankel structured is equivalent to the existence of a linear time-invariant system that fits the data and the rank constraint is related to a bound on the model complexity. In the special case of fitting by a static model, the data matrix and its low-rank approximation are unstructured.<p>
We outline applications in system theory (approximate realization, model reduction, output error and errors-in-variables identification), signal processing (harmonic retrieval, sum-of-damped exponentials and finite impulse response modeling), and computer algebra (approximate common divisor). Algorithms based on heuristics and local optimization methods are presented. Generalizations of the low-rank approximation problem result from different approximation criteria (e.g., weighted norm) and constraints on the data matrix (e.g., nonnegativity). Related problems are rank minimization and structured pseudospectra.
</blockquote>
<p><blockquote>
Keywords: Low-rank approximation, total least squares, system identification, errors-in-variables modeling, behaviors.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MN08">58</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and M.&nbsp;Niranjan.
 Approximate low-rank factorization with structured factors.
 <em>Comput. Statist. Data Anal.</em>, 54:3411--3420, 2008.
[&nbsp;<a href="j_bib.html#MN08">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csda.2009.06.003">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/267440/1/factorize_rev.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/267440/2/factorize.tar">software</a>&nbsp;| 
<a href="http://eprints.ecs.soton.ac.uk/17440/">http</a>&nbsp;]
<blockquote>
An approximate rank revealing factorization problem with structure constraints on the normalized factors is considered. Examples of structure, motivated by an application in microarray data analysis, are sparsity, nonnegativity, periodicity, and smoothness. In general, the approximate rank revealing factorization problem is nonconvex. An alternating projections algorithm is developed, which is globally convergent to a locally optimal solution. Although the algorithm is developed for a specific application in microarray data analysis, the approach is applicable to other types of structure.
</blockquote>
<p><blockquote>
Keywords: rank revealing factorization; numerical rank; low-rank approximation; maximum likelihood PCA; total least squares; errors-in-variables; microarray data.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MV05">59</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and S.&nbsp;Van Huffel.
 Overview of total least squares methods.
 <em>Signal Processing</em>, 87:2283--2302, 2007.
[&nbsp;<a href="j_bib.html#MV05">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.sigpro.2007.04.004">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263855/1/tls_overview.pdf">pdf</a>&nbsp;]
<blockquote>
We review the development and extensions of the classical total least squares method and describe algorithms for its generalization to weighted and structured approximation problems. In the generic case, the classical total least squares problem has a unique solution, which is given in analytic form in terms of the singular value decomposition of the data matrix. The weighted and structured total least squares problems have no such analytic solution and are currently solved numerically by local optimization methods. We explain how special structure of the weight matrix and the data matrix can be exploited for efficient cost function and first derivative computation. This allows to obtain computationally efficient solution methods. The total least squares family of methods has a wide range of applications in system theory, signal processing, and computer algebra. We describe the applications for deconvolution, linear prediction, and errors-in-variables system identification.
</blockquote>
<p><blockquote>
Keywords: Total least squares; Orthogonal regression; Errors-in-variables model; Deconvolution; Linear prediction; System identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="SKMV05">60</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Shklyar, A.&nbsp;Kukush, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 On the conic section fitting problem.
 <em>Journal of Multivariate Analysis</em>, 98:588--624, 2007.
[&nbsp;<a href="j_bib.html#SKMV05">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.jmva.2005.12.003">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263303/1/shklyar_published.pdf">pdf</a>&nbsp;]
<blockquote>
For the conic section problem adjusted least squares estimators (ALS) are considered.  Consistency of the translation invariant version of ALS estimator is proved. The similarity invariance of the ALS2 estimator is shown. The conditions for consistency of the ALS2 estimator are relaxed compared with the paper Kukush et al. (2004), Comput. Statist. Data Anal., Vol. 47, No. 1, 123--147.
</blockquote>
<p><blockquote>
Keywords: Adjusted least squares; Conic fitting; Consistent estimator; Ellipsoid fitting; Quadratic measurement error model
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MV05c">61</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and S.&nbsp;Van Huffel.
 Left vs right representations for solving weighted low rank
  approximation problems.
 <em>Linear Algebra Appl.</em>, 422:540--552, 2007.
[&nbsp;<a href="j_bib.html#MV05c">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.laa.2006.11.012">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263421/1/wtls_note_proof.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/wtls.tgz">software</a>&nbsp;]
<blockquote>
The weighted low-rank approximation problem in general has no analytical solution in terms of the singular value decomposition and is solved numerically using optimization methods. Four representations of the rank constraint that turn the abstract problem formulation into parameter optimization problems are presented. The parameter optimization problem is partially solved analytically, which results in an equivalent quadratically constrained problem. A commonly used re-parameterization avoids the quadratic constraint and makes the equivalent problem a nonlinear least squares problem, however, it might be necessary to change this re-parameterization during the iteration process. It is shown how the cost function can be computed efficiently in two special cases: row-wise and column-wise weighting.
</blockquote>
<p><blockquote>
Keywords: Weighted low-rank approximation, total least squares, parameter optimization.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="SMV06">62</a>]
</td>
<td class="bibtexitem">
M.&nbsp;Schuermans, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 An adapted version of the element-wise weighted TLS method for
  applications in chemometrics.
 <em>Chemometrics and Intelligent Laboratory Systems</em>, 85(1):40--46,
  2007.
[&nbsp;<a href="j_bib.html#SMV06">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.chemolab.2006.04.003">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263422/1/mieke2.pdf">pdf</a>&nbsp;]
<blockquote>
The Maximum Likelihood PCA (MLPCA) method has been devised in chemometrics as a generalization of the well-known PCA method in order to derive consistent estimators in the presence of errors with known error distribution. For similar reasons, the Total Least Squares (TLS) method has been generalized in the field of computational mathematics and engineering to maintain consistency of the parameter estimates in linear models with measurement errors of known distribution. In a previous paper [M. Schuermans, I. Markovsky, P.D. Wentzell, S. Van Huffel, On the equivalance between total least squares and maximum likelihood PCA, Anal. Chim. Acta, 544 (2005), 254–267], the tight equivalences between MLPCA and Element-wise Weighted TLS (EW-TLS) have been explored. The purpose of this paper is to adapt the EW-TLS method in order to make it useful for problems in chemometrics. We will present a computationally efficient algorithm and compare this algorithm with the standard EW-TLS algorithm and the MLPCA algorithm in computation time and convergence behaviour on chemical data.
</blockquote>
<p><blockquote>
Keywords: EW-TLS; MLPCA; Rank reduction; Measurement errors
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="KMV07">63</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Kukush, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 Estimation in a linear multivariate measurement error model with a
  change point in the data.
 <em>Comput. Statist. Data Anal.</em>, 52(2):1167--1182, 2007.
[&nbsp;<a href="j_bib.html#KMV07">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csda.2007.06.010">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263885/1/noisevar_stat_new_final.pdf">pdf</a>&nbsp;]
<blockquote>
A linear multivariate measurement error model <em>AX</em>=<em>B</em> is considered. The errors in [ <em>A</em>  <em>B</em> ] are row-wise finite dependent, and within each row, the errors may be correlated. Some of the columns may be observed without errors, and in addition the error covariance matrix may differ from row to row. The columns of the error matrix are united into two uncorrelated blocks, and in each block, the total covariance structure is supposed to be known up to a corresponding scalar factor. Moreover the row data are clustered into two groups, according to the behavior of the rows of true <em>A</em> matrix. The change point is unknown and estimated in the paper. After that, based on the method of corrected objective function, strongly consistent estimators of the scalar factors and&nbsp;<em>X</em> are constructed, as the numbers of rows in the clusters tend to infinity. Since Toeplitz/Hankel structure is allowed, the results are applicable to system identification, with a change point in the input data.
</blockquote>
<p><blockquote>
Keywords: Linear errors-in-variables model; Corrected objective function; Clustering; Dynamic errors-in-variables model; Consistent estimator.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MRPKV02">64</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, M.&nbsp;Rastello, A.&nbsp;Premoli, A.&nbsp;Kukush, and S.&nbsp;Van Huffel.
 The element-wise weighted total least squares problem.
 <em>Comput. Statist. Data Anal.</em>, 50(1):181--209, 2005.
[&nbsp;<a href="j_bib.html#MRPKV02">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csda.2004.07.014">DOI</a>&nbsp;| 
<a href="http://eprints.ecs.soton.ac.uk/13293/1/ewtls_published.pdf">pdf</a>&nbsp;| 
<a href="https://imarkovs.github.io/software/wtls.tgz">software</a>&nbsp;]
<blockquote>
We consider a new technique for parameter estimation in a linear measurement error model <em>AX</em> = <em>B</em>, <em>A</em> = <em>A</em><sub>0</sub> + <em>E</em><sub>A</sub>, <em>B</em> = <em>B</em><sub>0</sub> + <em>E</em><sub>B</sub>, <em>A</em><sub>0</sub><em>X</em><sub>0</sub>=<em>B</em><sub>0</sub> with row-wise independent and non-identically distributed measurement errors <em>E</em><sub>A</sub>, <em>E</em><sub>B</sub>. Here <em>A</em><sub>0</sub> and&nbsp;<em>B</em><sub>0</sub> are the true values of the measurements <em>A</em> and&nbsp;<em>B</em>, and&nbsp;<em>X</em><sub>0</sub> is the true value of the parameter&nbsp;<em>X</em>. The total least squares method yields an inconsistent estimate of the parameter in this case. We formulate a modified total least squares problem, called element-wise weighted total least squares, that provides a consistent estimator, i.e., the estimate&nbsp;X converges to the true value&nbsp;<em>X</em><sub>0</sub> as the number of measurements increases. The new estimator is a solution of an optimization problem with the parameter estimate&nbsp;X and the correction &Delta;<em>D</em> = [&Delta;<em>A</em>  &Delta;<em>B</em>], applied to the measured data&nbsp;<em>D</em>=[<em>A</em>  <em>B</em>], as decision variables. We derive an equivalent unconstrained problem by minimizing analytically over the correction&nbsp;&Delta;<em>D</em> and propose an iterative algorithm for its solution, based on the first order optimality condition. The algorithm is locally convergent with linear convergence rate. For large sample size the convergence rate tends to quadratic.
</blockquote>
<p><blockquote>
Keywords: Total least squares; Multivariate errors-in-variables model; Unequally sized errors; Non-convex optimization; Re-weighted least squares
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="KMV02e">65</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Kukush, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 Consistency of the structured total least squares estimator in a
  multivariate errors-in-variables model.
 <em>J. Statist. Plann. Inference</em>, 133(2):315--358, 2005.
[&nbsp;<a href="j_bib.html#KMV02e">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.jspi.2003.12.020">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263296/1/stls_published.pdf">pdf</a>&nbsp;]
<blockquote>
The structured total least squares estimator, defined via a constrained optimization problem, is a generalization of the total least squares estimator when the data matrix and the applied correction satisfy given structural constraints. In the paper, an affine structure with additional assumptions is considered. In particular, Toeplitz and Hankel structured, noise free and unstructured blocks are allowed simultaneously in the augmented data matrix. An equivalent optimization problem is derived that has as decision variables only the estimated parameters. The cost function of the equivalent problem is used to prove consistency of the structured total least squares estimator. The results for the general affine structured multivariate model are illustrated by examples of special models. Modification of the results for block-Hankel/Toeplitz structures is also given. As a by-product of the analysis of the cost function, an iterative algorithm for the computation of the structured total least squares estimator is proposed.
</blockquote>
<p><blockquote>
Keywords: Block-Hankel/Toeplitz structure; Consistency; Dynamic errors-in-variables model; Iterative algorithm; Structured total least squares; Total least squares.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MV03a">66</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, S.&nbsp;Van Huffel, and R.&nbsp;Pintelon.
 Block-Toeplitz/Hankel structured total least squares.
 <em>SIAM J. Matrix Anal. Appl.</em>, 26(4):1083--1099, 2005.
[&nbsp;<a href="j_bib.html#MV03a">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/S0895479803434902">DOI</a>&nbsp;| 
<a href="http://eprints.ecs.soton.ac.uk/13298/1/stls_block_published.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
A structured total least squares problem is considered, in which the extended data matrix is partitioned into blocks and each of the blocks is block-Toeplitz/Hankel structured, unstructured, or exact. An equivalent optimization problem is derived and its properties are established. The special structure of the equivalent problem enables to improve the computational efficiency of the numerical solution methods. By exploiting the structure, the computational complexity of the algorithms (local optimization methods) per iteration is linear in the sample size. Application of the method for system identification and for model reduction is illustrated by simulation examples. 
</blockquote>
<p><blockquote>
Keywords: Parameter estimation, Total least squares, Structured total least squares, System identification, Model reduction.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MDM03">67</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and B.&nbsp;De Moor.
 Linear dynamic filtering with noisy input and output.
 <em>Automatica</em>, 41(1):167--171, 2005.
[&nbsp;<a href="j_bib.html#MDM03">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2004.08.014">DOI</a>&nbsp;]
<blockquote>
State estimation problems for linear time-invariant systems with noisy inputs and outputs are considered. An efficient recursive algorithm for the smoothing problem is presented. The equivalence between the optimal filter and an appropriately modified Kalman filter is established. The optimal estimate of the input signal is derived from the optimal state estimate. The result shows that the noisy input/output filtering problem is not fundamentally different from the classical Kalman filtering problem.
</blockquote>
<p><blockquote>
Keywords: errors-in-variables, Kalman filtering, optimal smoothing, misfit, latency.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MWRDM04">68</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, J.&nbsp;C. Willems, P.&nbsp;Rapisarda, and B.&nbsp;De Moor.
 Algorithms for deterministic balanced subspace identification.
 <em>Automatica</em>, 41(5):755--766, 2005.
[&nbsp;<a href="j_bib.html#MWRDM04">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2004.10.007">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/262202/1/AutomaticaSubspaceID.pdf">pdf</a>&nbsp;| 
<a href="ftp://ftp.esat.kuleuven.be/pub/SISTA/markovsky/reports/05-122.tar.gz">software</a>&nbsp;]
<blockquote>
New algorithms for identification of a balanced state space representation are proposed. They are based on a procedure for estimation of the impulse response and sequential zero input responses directly from data. The proposed algorithms are more efficient than the existing alternatives that compute the whole Hankel matrix of Markov parameters. It is shown that the computations can be performed on Hankel matrices of the input-output data of various dimensions. By choosing wider matrices, we need persistency of excitation of smaller order. Moreover, this leads to computational savings and improved statistical accuracy when the data is noisy. Using a finite amount of input-output data, the existing algorithms compute finite time balanced representation and the identified models have a lower bound on the distance to an exact balanced representation. The proposed algorithm can approximate arbitrarily closely an exact balanced representation. Moreover, the finite time balancing parameter can be selected automatically by monitoring the decay of the impulse response. We show what is the optimal in terms of minimal identifiability condition partition of the data into &ldquo;past&rdquo; and &ldquo;future&rdquo;.
</blockquote>
<p><blockquote>
Keywords: Exact deterministic subspace identification; Balanced model reduction; Approximate system identification; MPUM.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MPV04a">69</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, J.&nbsp;C. Willems, S.&nbsp;Van Huffel, B.&nbsp;De Moor, and R.&nbsp;Pintelon.
 Application of structured total least squares for system
  identification and model reduction.
 <em>IEEE Trans. Automat. Contr.</em>, 50(10):1490--1500, 2005.
[&nbsp;<a href="j_bib.html#MPV04a">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TAC.2005.856643">DOI</a>&nbsp;| 
<a href="http://eprints.ecs.soton.ac.uk/13300/1/stls_appl_published.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-ident.html">software</a>&nbsp;]
<blockquote>
The following identification problem is considered: minimize the <em>l</em><sub>2</sub> norm of the difference between a given time series and an approximating one under the constraint that the approximating time series is a trajectory of a linear time invariant system of a fixed complexity. The complexity is measured by the input dimension and the maximum lag. The question leads to a problem that is known as the global total least squares problem and alternatively can be viewed as maximum likelihood identification in the errors-in-variables setup. Multiple time series and latent variables can be considered in the same setting. Special cases of the problem are autonomous system identification, approximate realization, and finite time optimal <em>l</em><sub>2</sub> model reduction. <p>
The identification problem is related to the structured total least squares problem. The paper presents an efficient software package that implements the theory. The proposed method and software are tested on data sets from the database for the identification of systems DAISY.
</blockquote>
<p><blockquote>
Keywords: Errors-in-variables, system identification, model reduction, structured total least squares, numerical software, DAISY, MPUM.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="WRMDM04">70</a>]
</td>
<td class="bibtexitem">
J.&nbsp;C. Willems, P.&nbsp;Rapisarda, I.&nbsp;Markovsky, and B.&nbsp;De Moor.
 A note on persistency of excitation.
 <em>Systems &amp; Control Lett.</em>, 54(4):325--329, 2005.
[&nbsp;<a href="j_bib.html#WRMDM04">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.sysconle.2004.09.003">DOI</a>&nbsp;| 
<a href="http://eprints.ecs.soton.ac.uk/12195/1/PersistencyExcitation.pdf">pdf</a>&nbsp;]
<blockquote>
We prove that if a component of the response signal of a controllable linear time-invariant system is persistently exciting of sufficiently high order, then the windows of the signal span the full system behavior. This is then applied to obtain conditions under which the state trajectory of a state representation spans the whole state space. The related question of when the matrix formed formed from a state sequence has linearly independent rows from the matrix formed from an input sequence and a finite number of its shifts is of central importance in subspace system identification. 
</blockquote>
<p><blockquote>
Keywords: Behavioral systems, persistency of excitation, lags, annihilators, system identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MV04">71</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and S.&nbsp;Van Huffel.
 High-performance numerical algorithms and software for structured
  total least squares.
 <em>J. Comput. Appl. Math.</em>, 180(2):311--331, 2005.
[&nbsp;<a href="j_bib.html#MV04">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.cam.2004.11.003">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263301/1/stls_pack_published.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
We present a software package for structured total least squares approximation problems. The allowed structures in the data matrix are block-Toeplitz, block-Hankel, unstructured, and exact. Combination of blocks with these structures can be specified. The computational complexity of the algorithms is&nbsp;<em>O</em>(<em>m</em>), where&nbsp;<em>m</em> is the sample size. We show simulation examples with different approximation problems. Application of the method for multivariable system identification is illustrated on examples from the database for identification of systems DAISY.

</blockquote>
<p><blockquote>
Keywords: Parameter estimation; Structured total least squares; Deconvolution; System identification; Numerical linear algebra.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="SMWV04">72</a>]
</td>
<td class="bibtexitem">
M.&nbsp;Schuermans, I.&nbsp;Markovsky, P.&nbsp;Wentzell, and S.&nbsp;Van Huffel.
 On the equivalence between total least squares and maximum likelihood
  PCA.
 <em>Analytica Chimica Acta</em>, 544(1--2):254--267, 2005.
[&nbsp;<a href="j_bib.html#SMWV04">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.aca.2004.12.059">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263302/1/mieke.pdf">pdf</a>&nbsp;]
<blockquote>
The maximum likelihood PCA (MLPCA) method has been devised in chemometrics as a generalization of the well-known PCA method in order to derive consistent estimators in the presence of errors with known error distribution. For similar reasons, the total least squares (TLS) method has been generalized in the field of computational mathematics and engineering to maintain consistency of the parameter estimates in linear models with measurement errors of known distribution. The basic motivation for TLS is the following. Let a set of multidimensional data points (vectors) be given. How can one obtain a linear model that explains these data? The idea is to modify all data points in such a way that some norm of the modification is minimized subject to the constraint that the modified vectors satisfy a linear relation. Although the name “total least squares” appeared in the literature only 25 years ago, this method of fitting is certainly not new and has a long history in the statistical literature, where the method is known as “orthogonal regression”, “errors-in-variables regression” or “measurement error modeling”. The purpose of this paper is to explore the tight equivalences between MLPCA and element-wise weighted TLS (EW-TLS). Despite their seemingly different problem formulation, it is shown that both methods can be reduced to the same mathematical kernel problem, i.e. finding the closest (in a certain sense) weighted low rank matrix approximation where the weight is derived from the distribution of the errors in the data. Different solution approaches, as used in MLPCA and EW-TLS, are discussed. In particular, we will discuss the weighted low rank approximation (WLRA), the MLPCA, the EW-TLS and the generalized TLS (GTLS) problems. These four approaches tackle an equivalent weighted low rank approximation problem, but different algorithms are used to come up with the best approximation matrix. We will compare their computation times on chemical data and discuss their convergence behavior.
</blockquote>
<p><blockquote>
Keywords: TLS; MLPCA; Rank reduction; Measurement errors
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="KMV02c">73</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Kukush, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 Consistent estimation in an implicit quadratic measurement error
  model.
 <em>Comput. Statist. Data Anal.</em>, 47(1):123--147, 2004.
[&nbsp;<a href="j_bib.html#KMV02c">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csda.2003.10.022">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263294/1/ellest_stat_published.pdf">pdf</a>&nbsp;| 
<a href="ftp://ftp.esat.kuleuven.ac.be/pub/SISTA/markovsky/reports/02-116b.m">software</a>&nbsp;]
<blockquote>
An adjusted least squares estimator is derived that yields a consistent estimate of the parameters of an implicit quadratic measurement error model. In addition, a consistent estimator for the measurement error noise variance is proposed. Important assumptions are: (1) all errors are uncorrelated identically distributed and (2) the error distribution is normal.  The estimators for the quadratic measurement error model are used to estimate consistently conic sections and ellipsoids. Simulation examples, comparing the adjusted least squares estimator with the ordinary least squares method and the orthogonal regression method, are shown for the ellipsoid fitting problem.
</blockquote>
<p><blockquote>
Keywords: Adjusted least squares; Conic fitting; Consistent estimator; Ellipsoid fitting; Quadratic measurement error model
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MKV02d">74</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, A.&nbsp;Kukush, and S.&nbsp;Van Huffel.
 Consistent least squares fitting of ellipsoids.
 <em>Numerische Mathematik</em>, 98(1):177--194, 2004.
[&nbsp;<a href="j_bib.html#MKV02d">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s00211-004-0526-9">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263295/1/ellest_comp_published.pdf">pdf</a>&nbsp;| 
<a href="ftp://ftp.esat.kuleuven.ac.be/pub/SISTA/markovsky/reports/02-116b.m">software</a>&nbsp;]
<blockquote>
A parameter estimation problem for ellipsoid fitting in the presence of measurement errors is considered. The ordinary least squares estimator is inconsistent, and due to the nonlinearity of the model, the orthogonal regression estimator is inconsistent as well, i.e., these estimators do not converge to the true value of the parameters, as the sample size tends to infinity. A consistent estimator is proposed, based on a proper correction of the ordinary least squares estimator. The correction is explicitly given in terms of the true value of the noise variance.
</blockquote>
<p><blockquote>
Keywords: adjusted least squares -- consistent estimator -- ellipsoid fitting -- orthogonal regression -- quadratic measurement error model -- total least squares
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="MVK02">75</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, S.&nbsp;Van Huffel, and A.&nbsp;Kukush.
 On the computation of the structured total least squares estimator.
 <em>Numer. Linear. Algebra Appl.</em>, 11:591--608, 2004.
[&nbsp;<a href="j_bib.html#MVK02">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1002/nla.361">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263297/1/stls_comp_published.pdf">pdf</a>&nbsp;| 
<a href="http://slra.github.io/software-slra.html">software</a>&nbsp;]
<blockquote>
A multivariate structured total least squares problem is considered, in which the extended data matrix is partitioned into blocks and each of the blocks is Toeplitz/Hankel structured, unstructured, or noise free. Two types of numerical solution methods for this problem are proposed: i) standard local optimization methods in combination with efficient evaluation of the cost function and its first derivative, and ii) an iterative procedure proposed originally for the element-wise weighted total least squares problem. The computational efficiency of the proposed methods is compared with this of alternative methods.
</blockquote>
<p><blockquote>
Keywords: parameter estimation; total least squares; structured total least squares; system identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="KMV01c">76</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Kukush, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 Consistent estimation in the bilinear multivariate
  errors-in-variables model.
 <em>Metrika</em>, 57(3):253--285, 2003.
[&nbsp;<a href="j_bib.html#KMV01c">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s001840200217">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263292/1/axb_published.pdf">pdf</a>&nbsp;]
<blockquote>
A multivariate measurement error model <em>AX</em> = <em>B</em>  is considered. The errors in [<em>A</em>  <em>B</em>] are rowwise independent, but within each row the errors may be correlated. Some of the columns are observed without errors, and in addition the error covariance matrices may differ from row to row. The total covariance structure of the errors is supposed to be known up to a scalar factor. The fully weighted total least squares estimator of <em>X</em> is studied, which in the case of normal errors coincides with the maximum likelihood estimator. We give mild conditions for weak and strong consistency of the estimator, when the number of rows in <em>A</em> increases. The results generalize the conditions of Gallo given for a univariate homoscedastic model (where <em>B</em> is a vector), and extend the conditions of Gleser given for the multivariate homoscedastic model. We derive the objective function for the estimator and propose an iteratively reweighted numerical procedure.
</blockquote>
<p><blockquote>
Keywords: linear errors-in-variables model, elementwise-weighted total least squares, consistency, iteratively reweighted procedure
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="KMV01b">77</a>]
</td>
<td class="bibtexitem">
A.&nbsp;Kukush, I.&nbsp;Markovsky, and S.&nbsp;Van Huffel.
 Consistent fundamental matrix estimation in a quadratic measurement
  error model arising in motion analysis.
 <em>Comput. Statist. Data Anal.</em>, 41(1):3--18, 2002.
[&nbsp;<a href="j_bib.html#KMV01b">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/S0167-9473(02)00068-3">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/263294/1/ellest_stat_published.pdf">pdf</a>&nbsp;]
<blockquote>
A bilinear multivariate errors-in-variables model is considered. It corresponds to an overdetermined set of linear equations <em>AXB</em>=<em>C</em>, where <em>A</em> is <em>m</em>&#215;<em>n</em>, <em>B</em> is <em>p</em>&#215;<em>q</em>, and <em>A</em>, <em>B</em>, <em>C</em> are perturbed by errors. The total least squares estimator is inconsistent in this case. An adjusted least squares estimator is constructed, which converges to the true value of <em>X</em>, as <em>m</em> and <em>q</em> go to infinity. A small sample modification of the estimator is presented, which is more stable for small <em>m</em> and <em>q</em> and is asymptotically equivalent to the adjusted least squares estimator. The theoretical results are confirmed by a simulation study.
</blockquote>
<p><blockquote>
Keywords: bilinear multivariate measurement error models, errors-in-variables models, adjusted least squares, consistency, asymptotic normality, small sample modification
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="LHM99">78</a>]
</td>
<td class="bibtexitem">
M.&nbsp;Lemmon, K.&nbsp;He, and I.&nbsp;Markovsky.
 Supervisory hybrid systems.
 <em>IEEE Control Systems Magazine</em>, 19(4):42--55, August 1999.
[&nbsp;<a href="j_bib.html#LHM99">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/37.777788">DOI</a>&nbsp;]
<blockquote>
Supervisory hybrid systems are systems generating a mixture of continuous-valued and discrete-valued signals. This systems paradigm is particularly useful in modeling applications where high-level decision making is used to supervise process behavior. Hybrid system methodologies are also applicable to switched systems where the system switches between various setpoints or operational modes to extend its effective operating range. Hybrid systems, therefore, embrace a diverse set of applications. There has been considerable activity in the area of hybrid systems theory, and this article provides an introduction to some of the basic concepts and trends in this emergent field. The term hybrid refers to a mixing of two fundamentally different types of objects or methods. The paper deals with supervisory hybrid systems. Supervisory hybrid systems are systems that combine discrete event and continuous-valued dynamics. The article is organized as follows. We first provide an example of a hybrid system, to be used throughout as a pedagogical tool illustrating various concepts in hybrid systems theory. We then discuss modeling frameworks for hybrid systems, paying specific attention to the hybrid automaton. Not only may the system have a hybrid character, but the specifications on desired system behaviors may also be hybrid. The article also discusses specification logics that express system requirements on both the discrete and continuous states of the system. The article continues with a survey of current methods and concepts used to verify or validate desired system behaviors, and concludes with a survey of current methods for hybrid control system synthesis
</blockquote>
<p>
</td>
</tr>
</table><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
